{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from gridworld.environment import GridWorldEnv\n",
    "from gridworld.utils import plotVTableInGrid, plotQTableInGrid\n",
    "from gridworld.utils import VTableVisualizer, QTableVisualizer\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES = [0, 1, 2, 3, 4]\n",
    "P = { 0 : { 'facebook' : [(1.0, 2, -1., False)],\n",
    "            'study' : [(1.0, 1, -2., False)] },\n",
    "      1 : { 'study' : [(1.0, 3, -2., False)],\n",
    "            'sleep' : [(1.0, 4, 0., False)] },\n",
    "      2 : { 'facebook' : [(1.0, 2, -1., False)],\n",
    "            'quit' : [(1.0, 0, 0., False)] },\n",
    "      3 : { 'study' : [(1.0, 4, 10., False)],\n",
    "            'pub' : [(0.2, 0, 1., False), (0.4, 1, 1., False), (0.4, 3, 1., False)] },\n",
    "      4 : { 'end' : [(1.0, 4, 0., True)] } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving...: 100%|██████████| 100/100 [00:00<00:00, 45358.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6.0, 1: 8.0, 2: 6.0, 3: 10.0, 4: 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# policy evaluation: how good is my policy???\n",
    "\n",
    "def policy_random( s, a ) :\n",
    "    return 1. / len( list( P[s].keys() ) )\n",
    "\n",
    "def policy_responsible( s, a ) :\n",
    "    if 'study' in P[s] :\n",
    "        return 1.0 if a == 'study' else 0.0\n",
    "    elif 'quit' in P[s] :\n",
    "        return 1.0 if a == 'quit' else 0.0\n",
    "    else :\n",
    "        return policy_random( s, a )\n",
    "\n",
    "policy_fn = policy_responsible\n",
    "## policy_fn = policy_random\n",
    "\n",
    "V_pi = defaultdict( lambda : 0.0 )\n",
    "N_iters = 100\n",
    "GAMMA = 1.0\n",
    "\n",
    "for i_iter in tqdm( range( N_iters ), desc = 'Backing-up...' ) : \n",
    "    # keep a copy for the bellman backups (no in-place updates)\n",
    "    V_old = V_pi.copy()\n",
    "    # do a bellman backup for every state\n",
    "    for s in STATES :\n",
    "        V_pi[s] = 0.0 # clear the state-value to be accumulated in the table\n",
    "        actions = list( P[s].keys() )\n",
    "        for a in actions :\n",
    "            a_prob = policy_fn( s, a )\n",
    "            for t_prob, snext, reward, _ in P[s][a] :\n",
    "                V_pi[s] += a_prob * t_prob * ( reward + GAMMA * V_old[snext] )\n",
    "\n",
    "print( dict(V_pi) )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Improving...:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Backing-up...:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Improving...: 100%|██████████| 10/10 [00:00<00:00, 359.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6.0, 1: 8.0, 2: 6.0, 3: 10.0, 4: 0.0}\n",
      "{0: {'facebook': 0.0, 'study': 1.0}, 1: {'study': 1.0, 'sleep': 0.0}, 2: {'quit': 1.0, 'facebook': 0.0}, 3: {'pub': 0.0, 'study': 1.0}, 4: {'end': 1.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# policy iteration: what is the optimal policy???\n",
    "pi = { 0 : { 'facebook' : 0.5, 'study' : 0.5 },\n",
    "       1 : { 'study' : 0.5, 'sleep' : 0.5 },\n",
    "       2 : { 'quit' : 0.5, 'facebook' : 0.5 },\n",
    "       3 : { 'pub' : 0.5, 'study' : 0.5 }, \n",
    "       4 : { 'end' : 1.0 } }\n",
    "\n",
    "V_pi = defaultdict( lambda : 0.0 )\n",
    "N_iter_improv = 10\n",
    "\n",
    "for _ in tqdm( range( N_iter_improv ), desc = 'Improving...' ) :\n",
    "    # policy-evaluation\n",
    "    for i_iter in tqdm( range( N_iters ), desc = 'Backing-up...', leave = False ) : \n",
    "        # keep a copy for the bellman backups (no in-place updates)\n",
    "        V_old = V_pi.copy()\n",
    "        # do a bellman backup for every state\n",
    "        for s in STATES :\n",
    "            V_pi[s] = 0.0 # clear the state-value to be accumulated in the table\n",
    "            actions = list( P[s].keys() )\n",
    "            for a in actions :\n",
    "                a_prob = pi[s][a]\n",
    "                for t_prob, snext, reward, _ in P[s][a] :\n",
    "                    V_pi[s] += a_prob * t_prob * ( reward + GAMMA * V_old[snext] )\n",
    "    \n",
    "    # policy-improvement\n",
    "    for s in STATES :\n",
    "        actions = list( P[s].keys() )\n",
    "        Qs = defaultdict( lambda : 0.0 )\n",
    "        for a in actions :\n",
    "            a_prob = pi[s][a]\n",
    "            for t_prob, snext, reward, _ in P[s][a] :\n",
    "                Qs[a] += a_prob * t_prob * ( reward + GAMMA * V_pi[snext] )\n",
    "                \n",
    "        for a in actions :\n",
    "            pi[s][a] = 1.0 if a == max(Qs) else 0.\n",
    "\n",
    "print( dict(V_pi) )\n",
    "print( pi )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value iteration: what is the optimal value function???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
